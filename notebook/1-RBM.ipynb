{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boltzmann Machines: A Comprehensive Introduction\n",
    "\n",
    "## Overview\n",
    "A **Boltzmann Machine (BM)** is a stochastic recurrent neural network inspired by statistical mechanics. Developed by Geoffrey Hinton and Terrence Sejnowski (1985), it serves as a **generative model** for learning complex probability distributions.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "### 1. Architecture\n",
    "- **Neurons**: Binary units (typically {0,1} or {-1,1})\n",
    "- **Connections**: \n",
    "  - Symmetric weights (wᵢⱼ = wⱼᵢ)\n",
    "  - No self-connections\n",
    "- **Layers**:\n",
    "  - **Visible units**: Represent observed data\n",
    "  - **Hidden units**: Capture latent features\n",
    "\n",
    "### 2. Energy Function\n",
    "The energy of state (v,h) is defined as:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "class RBM:\n",
    "    def __init__(self, n_visible, n_hidden, learning_rate=0.1, epochs=100):\n",
    "        self.n_visible = n_visible\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        # Initialize weights and biases\n",
    "        self.W = np.random.randn(n_visible, n_hidden) * 0.01\n",
    "        self.a = np.zeros(n_visible)  # Visible layer bias\n",
    "        self.b = np.zeros(n_hidden)   # Hidden layer bias\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sample_hidden(self, v):\n",
    "        # Sample hidden layer given visible layer\n",
    "        h_prob = self.sigmoid(np.dot(v, self.W) + self.b)\n",
    "        h_sample = np.random.binomial(1, h_prob)\n",
    "        return h_prob, h_sample\n",
    "    \n",
    "    def sample_visible(self, h):\n",
    "        # Sample visible layer given hidden layer\n",
    "        v_prob = self.sigmoid(np.dot(h, self.W.T) + self.a)\n",
    "        v_sample = np.random.binomial(1, v_prob)\n",
    "        return v_prob, v_sample\n",
    "    \n",
    "    def train(self, X):\n",
    "        errors = []\n",
    "        for epoch in range(self.epochs):\n",
    "            # Forward pass: compute hidden layer probabilities and sample\n",
    "            h0_prob, h0_sample = self.sample_hidden(X)\n",
    "            \n",
    "            # Backward pass: reconstruct visible layer and sample hidden layer\n",
    "            v1_prob, v1_sample = self.sample_visible(h0_sample)\n",
    "            h1_prob, h1_sample = self.sample_hidden(v1_sample)\n",
    "            \n",
    "            # Update weights and biases using Contrastive Divergence (CD-1)\n",
    "            positive_grad = np.dot(X.T, h0_prob)\n",
    "            negative_grad = np.dot(v1_sample.T, h1_prob)\n",
    "            \n",
    "            self.W += self.lr * (positive_grad - negative_grad) / X.shape[0]\n",
    "            self.a += self.lr * np.mean(X - v1_sample, axis=0)\n",
    "            self.b += self.lr * np.mean(h0_prob - h1_prob, axis=0)\n",
    "            \n",
    "            # Calculate reconstruction error\n",
    "            error = np.mean((X - v1_prob) ** 2)\n",
    "            errors.append(error)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch {epoch}, Error: {error:.4f}\")\n",
    "        \n",
    "        return errors\n",
    "    \n",
    "    def reconstruct(self, X):\n",
    "        _, h = self.sample_hidden(X)\n",
    "        _, v = self.sample_visible(h)\n",
    "        return v\n",
    "\n",
    "# Load MNIST dataset (binarized)\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X = mnist.data.astype('float32') / 255.0\n",
    "X = Binarizer(threshold=0.5).fit_transform(X)  # Binarize\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train RBM\n",
    "rbm = RBM(n_visible=784, n_hidden=64, learning_rate=0.01, epochs=50)\n",
    "errors = rbm.train(X_train)\n",
    "\n",
    "# Visualize training error\n",
    "plt.plot(errors)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Reconstruction Error\")\n",
    "plt.title(\"RBM Training Error\")\n",
    "plt.show()\n",
    "\n",
    "# Test reconstruction\n",
    "test_sample = X_test[:5]\n",
    "reconstructed = rbm.reconstruct(test_sample)\n",
    "\n",
    "# Visualize original vs. reconstructed images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 4))\n",
    "for i in range(5):\n",
    "    axes[0, i].imshow(test_sample[i].reshape(28, 28), cmap='gray')\n",
    "    axes[0, i].set_title(\"Original\")\n",
    "    axes[0, i].axis('off')\n",
    "    axes[1, i].imshow(reconstructed[i].reshape(28, 28), cmap='gray')\n",
    "    axes[1, i].set_title(\"Reconstructed\")\n",
    "    axes[1, i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
