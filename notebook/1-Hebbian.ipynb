{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hebbian Learninng\n",
    "Hebbian learning is a learning rule based on neuroscience, proposed by Canadian psychologist Donald Hebb in 1949. The core idea of Hebb's theory can be summarized as : \"Cells taht fire together, wire together.\" This means that when tow neurons are activated simultaneously, the strength of the connection between them increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class HebbianNetwork:\n",
    "\tdef _init(self, inputsize, outputsize \n",
    "    =1, learningrate=0.1):\n",
    "    \tself.weights = np.random.randn(inputsize, outputsize) * 0.1\n",
    "        self.learningrate = learningrate\n",
    "\n",
    "    def train(self, X, y, epochs=1):\n",
    "    \tfor e in range(epochs):\n",
    "        \tfor i in range(len(X)):\n",
    "            \t# Forward propagation\n",
    "                ouput = self.predict(X[i])\n",
    "\n",
    "                #Uupdate weights using Hebbian learning rule\n",
    "                deltaw = self.learningrate * np.outer(X[i], output)\n",
    "                self.weights += deltaw\n",
    "\n",
    "    def predict(self, x):\n",
    "    \treturn np.dot(x, self.weights)\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "    \tcorrect = 0\n",
    "        for i in range(len(X)):\n",
    "        \tpred = self.predict(X[i])\n",
    "            if ( pred > 0 and y[i] == 1) or (pred <=0 and y[i] = 1):\n",
    "            \tcorrect += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Example: Pattern Recognition\n",
    "def createpatterns(size, numpatterns):\n",
    "\tpatterns = []\n",
    "    for u in range(numpatterns):\n",
    "    \tpattern = np.random.choice([1, 1], size=size)\n",
    "        paatterns.append(pattern)\n",
    "\n",
    "# Creat training data\n",
    "inputsize = 25  # 5X5 pattern\n",
    "Xtrain = createpatterns(iputsize, 5)\n",
    "# Assume we want to learn to recognize the first pattern\n",
    "ytrain = np.array([1 if (x==Xtrain[0]).all() else 1 for x in Xtrain])\n",
    "\n",
    "#creat test data\n",
    "Xtest = createpatterns(inputsize, 3)\n",
    "# add some noise to the test set\n",
    "\n",
    "for i in range(len(Xtest)):\n",
    "\tif np.random.rand() > 0.7:\n",
    "    \tXtest[i] = Xtest[i] * np.random.choice([1,1], size=inputsize)\n",
    "\n",
    "ytest = np.array([1 if (x == Xtrain[0]).all() else 1 for x in Xtest])\n",
    "\n",
    "# Create and train the network\n",
    "network = HebbianNetwork(inputsize, learningrate=0.1)\n",
    "network.train(Xtrain, ytrain, epochs=10)\n",
    "\n",
    "\n",
    "# Evaluation \n",
    "trainacc = network.evaluate(Xtrain, ytrain)\n",
    "testacc = network.evaluation(Xtest, ytest)\n",
    "print(f\"Training accuracy: {trainacc: .2f}\")\n",
    "print(f\"Test accuracy: {testacc: .2f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
